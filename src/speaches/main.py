from __future__ import annotations

import logging
import platform

import uvicorn

from fastapi import (
    FastAPI,
)
from fastapi.middleware.cors import CORSMiddleware

from speaches.dependencies import ApiKeyDependency, get_config
from speaches.logger import setup_logger
from speaches.routers.misc import (
    router as misc_router,
)
from speaches.routers.models import (
    router as models_router,
)
from speaches.routers.speech import (
    router as speech_router,
)
from speaches.routers.stt import (
    router as stt_router,
)
from speaches.routers.vad import (
    router as vad_router,
)
from speaches.routers.diarization import (
    router as diarization_router,
)
from contextlib import asynccontextmanager
import os

from speaches.dependencies import get_model_manager, get_piper_model_manager, get_diarization_model

DESCRIPTION = """
# Speaches - Ð¡ÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ Ð¸ ÑÐ¸Ð½Ñ‚ÐµÐ·Ð° Ñ€ÐµÑ‡Ð¸

## ðŸ“ ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ
Ð£Ð½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ð°ÑƒÐ´Ð¸Ð¾, Ð²ÐºÐ»ÑŽÑ‡Ð°ÑŽÑ‰Ð¸Ð¹ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÑ‡Ð¸,
Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð³Ð¾Ð²Ð¾Ñ€ÑÑ‰Ð¸Ñ… Ð¸ ÑÐ¸Ð½Ñ‚ÐµÐ· Ñ€ÐµÑ‡Ð¸.

## ðŸš€ ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸
1. Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÑ‡Ð¸ (STT):
   - ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Whisper Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
   - Streaming Ñ€ÐµÐ¶Ð¸Ð¼ Ð´Ð»Ñ real-time Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸
   - VAD Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ñ‚Ð¸ÑˆÐ¸Ð½Ñ‹
   - ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° hotwords Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸
   - Ð Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹ Ð²Ñ‹Ð²Ð¾Ð´Ð° (text, json, vtt, srt)

2. Ð”Ð¸Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ (Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð³Ð¾Ð²Ð¾Ñ€ÑÑ‰Ð¸Ñ…):
   - Ð‘Ð°Ð·Ð¾Ð²Ð°Ñ Ð´Ð¸Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ (/diarize)
   - Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ð°Ñ Ð´Ð¸Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸ÐµÐ¹ (/v1/audio/diarization)
   - ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° Ð³Ð¾Ð²Ð¾Ñ€ÑÑ‰Ð¸Ñ…
   - Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚ÐºÐ¸ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð³Ð¾Ð²Ð¾Ñ€ÑÑ‰ÐµÐ³Ð¾

3. Ð¡Ð¸Ð½Ñ‚ÐµÐ· Ñ€ÐµÑ‡Ð¸ (TTS):
   - ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Kokoro Ð¸ Piper
   - Ð Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ ÑÐ·Ñ‹ÐºÐ¸ Ð¸ Ð³Ð¾Ð»Ð¾ÑÐ°
   - ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ ÑÐ¸Ð½Ñ‚ÐµÐ·Ð°
   - Streaming Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð° Ð°ÑƒÐ´Ð¸Ð¾
   - Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹: mp3, wav, ogg

## ðŸ› ï¸ ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ ÑÐ½Ð´Ð¿Ð¾Ð¸Ð½Ñ‚Ñ‹
1. Speech-to-Text (STT):
   - POST /v1/audio/transcriptions - Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÑ‡Ð¸
   
2. Ð”Ð¸Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ:
   - POST /diarize - Ð‘Ð°Ð·Ð¾Ð²Ð°Ñ Ð´Ð¸Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ
   - POST /v1/audio/diarization - Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ð°Ñ Ð´Ð¸Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ
   
3. Text-to-Speech (TTS):
   - POST /v1/audio/speech - Ð¡Ð¸Ð½Ñ‚ÐµÐ· Ñ€ÐµÑ‡Ð¸

## ðŸ“¦ ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
- Whisper (STT): faster-whisper-large-v3-turbo
- Pyannote (Ð”Ð¸Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ): pyannote/speaker-diarization-3.1
- TTS: rhasspy/piper-voices

## âš™ï¸ ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ
- ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° GPU Ð´Ð»Ñ ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ñ
- ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° Ð±Ð°Ñ‚Ñ‡Ð°
- ÐšÐ°ÑÑ‚Ð¾Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
- Ð£Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸

## ðŸ“‹ ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ
### 1. Ð”Ð¸Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð°ÑƒÐ´Ð¸Ð¾
```bash
curl -X POST "http://localhost:8000/v1/audio/diarization" \
        -H "Content-Type: multipart/form-data" \
        -F "file=@audio.wav" \
        -F "model=base" \
        -F "language=ru" \
        -F "response_format=verbose_json" \
        -F "num_speakers=2" \
        -F "timestamp_granularities=segment" \
        -F "timestamp_granularities=word"
```
ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼:
```json
[
  {
    "id": 1,
    "start": 0.0,
    "end": 2.0,
    "text": " ÐŸÑ€Ð¸Ð²ÐµÑ‚! ÐœÐµÐ½Ñ Ð·Ð¾Ð²ÑƒÑ‚ ÐŸÐ°Ð¹Ð¿ÐµÑ€!",
    "speaker": "SPEAKER_00"
  }
]
```

### 2. Ð¢Ð¾Ñ‡ÐµÑ‡Ð½Ð°Ñ Ð´Ð¸Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ
```bash
curl -X POST http://localhost:8000/diarize \
        -F "audio=@audio.wav" \
        -F "num_speakers=2"
```
ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼:
```json
{
  "diarization_segments": [
    {
      "speaker": "SPEAKER_00",
      "start": 0.03096875,
      "end": 1.9209687500000001
    }
  ],
  "success": true,
  "error": null
}
```

### 3. STT
```bash
curl http://localhost:8000/v1/audio/transcriptions -F "file=@audio.wav"
```
ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼:
```json
{
  "text": "ÐŸÑ€Ð¸Ð²ÐµÑ‚, Ð¼ÐµÐ½Ñ Ð·Ð¾Ð²ÑƒÑ‚ ÐŸÐ°Ð¹Ð¿ÐµÑ€."
}
```

### 4. TTS
```bash
curl http://localhost:8000/v1/audio/speech \
        -H "Content-Type: application/json" \
        -d '{
  "model": "rhasspy/piper-voices",
  "input": "ÐŸÑ€Ð¸Ð²ÐµÑ‚, Ð¼ÐµÐ½Ñ Ð·Ð¾Ð²ÑƒÑ‚ ÐŸÐ°Ð¹Ð¿ÐµÑ€!",
  "voice": "ru_RU-denis-medium",
  "response_format": "wav",
  "speed": 1,
  "sample_rate": 8000
}' \
        --output audio.wav
```
ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼: audio.wav

"""

# https://swagger.io/docs/specification/v3_0/grouping-operations-with-tags/
# https://fastapi.tiangolo.com/tutorial/metadata/#metadata-for-tags
TAGS_METADATA = [
    {"name": "automatic-speech-recognition"},
    {"name": "speech-to-text"},
    {"name": "models"},
    {"name": "diagnostic"},
    {
        "name": "experimental",
        "description": "Not meant for public use yet. May change or be removed at any time.",
    },
]

@asynccontextmanager
async def lifespan(app: FastAPI):
    print('Starting up')
    _ = get_diarization_model()
    model_managers = {
        os.getenv('WHISPER__MODEL', None): get_model_manager(), 
        "ru_RU-denis-medium": get_piper_model_manager()
    }
    for name, model in model_managers.items():
        print('Loading: ', type(model).__name__)
        if name:
            with model.load_model(name) as model_instance:
                pass
    yield
    print('Shutting down')
    


def create_app() -> FastAPI:
    config = get_config()  # HACK
    setup_logger(config.log_level)
    logger = logging.getLogger(__name__)

    logger.debug(f"Config: {config}")

    if platform.machine() == "x86_64":
        logger.warning("`POST /v1/audio/speech` with `model=rhasspy/piper-voices` is only supported on x86_64 machines")

    dependencies = []
    if config.api_key is not None:
        dependencies.append(ApiKeyDependency)

    app = FastAPI(
        dependencies=dependencies, 
        openapi_tags=TAGS_METADATA, 
        description=DESCRIPTION,
        lifespan=lifespan,
    )
    routers = [
            stt_router, models_router, 
            misc_router, speech_router, 
            vad_router, diarization_router
        ]
    for router in routers:
        app.include_router(router)

    if config.allow_origins is not None:
        app.add_middleware(
            CORSMiddleware,
            allow_origins=config.allow_origins,
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )

    if config.enable_ui:
        import gradio as gr

        from speaches.gradio_app import create_gradio_demo

        app = gr.mount_gradio_app(app, create_gradio_demo(config), path="/")

    return app


if __name__ == "__main__":
    config = get_config()
    uvicorn.run(
        app=create_app,
        host=config.host,
        port=config.port,
        factory=True,
    )